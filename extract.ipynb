{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.3.10)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytesseract) (9.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from packaging>=21.3->pytesseract) (3.0.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\lmy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdf2image in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.16.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\lmy\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pdf2image) (9.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\lmy\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# install packages\n",
    "!pip install pytesseract\n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from a PDF file\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  \n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    # Convert the PDF to a list of PIL Image objects\n",
    "    images = convert_from_path(pdf_path)\n",
    "    text_list = []\n",
    "    # Loop through each page of the PDF and extract text using Tesseract\n",
    "    for image in images:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        text_list.append(text)\n",
    "    # Combine text from all pages into a single string\n",
    "    text = '\\n'.join(text_list)\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for column A to N, not include K and L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pattern = r'\\b\\d{1,2}\\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s+\\d{4}\\b'\n",
    "# Extract year (A) and date (J)\n",
    "def extract_date(text):\n",
    "    date_match = re.search(date_pattern, text)\n",
    "    if date_match:\n",
    "        date = date_match.group(0)\n",
    "        date_obj = datetime.strptime(date, '%d %B %Y')\n",
    "        # change mm/dd/yyyy format\n",
    "        new_date = date_obj.strftime('%m/%d/%Y') #column J\n",
    "        year = new_date[-4:] #column A\n",
    "    else:\n",
    "        year = date = 'N/A'\n",
    "        print(\"No date found\")\n",
    "    return year, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "council_pattern1 = r\"(?<=session).*?(?=Agenda)\"\n",
    "council_pattern2 = r'([A-Z][A-Za-z]+\\s)+(COUNCIL|Council)'\n",
    "\n",
    "# Extract council/committe name (B)\n",
    "def extract_council(text):\n",
    "    match1 = re.search(council_pattern1, text, re.DOTALL)\n",
    "    match2 = re.search(council_pattern2, text, re.DOTALL)\n",
    "    council = 'N/A'\n",
    "    # handle the council after session\n",
    "    if match1:\n",
    "        council = match1.group(0).strip()\n",
    "    # handle the council before session\n",
    "    if match2:\n",
    "        council = match2.group(0).strip()\n",
    "    if 'Economic and Social' in text:\n",
    "        council = 'Economic and Social Council'\n",
    "    if council == 'N/A':\n",
    "        print(\"Council Name not found\")\n",
    "    return remove_empty(council)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(text):\n",
    "    if text == None:\n",
    "        return 'N/A'\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.strip()\n",
    "    if text == '':\n",
    "        return 'N/A'\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_pattern = r'(?P<session>[\\w-]+\\s*session)'\n",
    "# Extract session (C)\n",
    "def extract_session(text):\n",
    "    #print(text)\n",
    "    #print(remove_empty(text))\n",
    "    match = re.search(session_pattern, text)\n",
    "    if match:\n",
    "        session = match.group(\"session\")\n",
    "    else:\n",
    "        session = 'N/A'\n",
    "        print(\"Session information not found.\")\n",
    "    return remove_empty(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_pattern = r'^([A-Za-z]+$)|[A-Za-z]+, *[A-Za-z]+'\n",
    "def helper_extractCountries(text):\n",
    "    footnote = ''\n",
    "    countries = ''\n",
    "    for part in text:\n",
    "        #print(part)\n",
    "        match = re.search(country_pattern, part)\n",
    "        if match:\n",
    "            if part[-2] == ':':\n",
    "                countries += part[:-2]\n",
    "            else:\n",
    "                countries += part\n",
    "        else:\n",
    "            footnote += part\n",
    "    return countries, footnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda_pattern = r'Agenda item (\\d+)(?: \\((\\w+)\\))?(?:\\n\\n)?' # match single agenda item\n",
    "agendas_pattern = r'Agenda items (\\d+ \\(\\w+\\)? and \\d+)'  # match agenda items\n",
    "draft_pattern = r':? *([\\w ]*|[\\n]*)? ?draft' #': *([\\w ]*)?draft'\n",
    "\n",
    "# Extract Agenda item (D), Agenda detail (E), and countries (F)\n",
    "def extract_agenda_countries(text):\n",
    "    # match agenda item\n",
    "    match1 = re.search(agenda_pattern, text)\n",
    "    match2 = re.search(agendas_pattern, text)\n",
    "    start_index = 0\n",
    "    if match1:           # handle single agenda item\n",
    "        #print(\"single agenda\")\n",
    "        agenda_item_number = match1.group(1)\n",
    "        agenda_item_letter = match1.group(2)\n",
    "        if agenda_item_letter is not None:\n",
    "            agenda_item = f\"{agenda_item_number} ({agenda_item_letter})\"\n",
    "        else:\n",
    "            agenda_item = agenda_item_number\n",
    "        \n",
    "        start_index = match1.end()\n",
    "    elif match2:         # handle multiple agenda item\n",
    "        #print(\"multiple agenda\")\n",
    "        agenda_item = match2.group(1)\n",
    "        start_index = match2.end()\n",
    "    else:              \n",
    "        print(\"Agenda not found\")\n",
    "    \n",
    "    if start_index != 0:\n",
    "        match3 = re.search(draft_pattern, text[start_index:], re.DOTALL)\n",
    "        if match3:\n",
    "            end_index = start_index + match3.start()\n",
    "            content = text[start_index:end_index]\n",
    "            #print(content)\n",
    "            parts = content.split(\"\\n\\n\")\n",
    "            parts = [s for s in parts if s != '']\n",
    "            #print(parts)\n",
    "            agenda_detail = parts[0]\n",
    "            countries, footnote = helper_extractCountries(parts[1:])\n",
    "            #print(footnote, countries)\n",
    "        else:\n",
    "            print('Agenda match3 error')\n",
    "    \n",
    "    return agenda_item, remove_empty(agenda_detail), remove_empty(countries), footnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    # delete extracted text\n",
    "    split_text = re.split(draft_pattern, text, flags=re.IGNORECASE)\n",
    "    #print(split_text)\n",
    "    #print(len(split_text))\n",
    "    part1_text = split_text[0]\n",
    "    part2_text = split_text[2:]\n",
    "    part2_text = '\\n\\n'.join(part2_text)\n",
    "    return part1_text, part2_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_head_pattern = r'(The General Assembly,|The Commission on Human Rights,|The Human Rights Council |The Economic and Social Council,|1\\.)'\n",
    "number_title_pattern = r'^\\s*(\\d{4})?/?\\W*(.*)'\n",
    "\n",
    "# Extract body title number (G) and body title （H）\n",
    "def extract_body_title(text):\n",
    "    title_body_text = re.split(text_head_pattern, text)\n",
    "    body = ' '.join(title_body_text[1:])\n",
    "    title_text = title_body_text[0]\n",
    "    title_text = title_text.replace('\\n', ' ')\n",
    "    \n",
    "    match1 = re.search(r'[A-Z\\d]', title_text)\n",
    "    if match1:\n",
    "        index = match1.start()\n",
    "        title_text = title_text[index-1:]\n",
    "        match2 = re.match(number_title_pattern, title_text)\n",
    "        if match2:\n",
    "            title_number = match2.group(1)\n",
    "            title = match2.group(2)\n",
    "    else:\n",
    "        title_number = 'N/A'\n",
    "        title = 'N/A'\n",
    "\n",
    "    if remove_empty(title) == remove_empty(title_text) and len(title) > 400:\n",
    "        #print(True)\n",
    "        match3 = re.search(r\"[A-Z].*?[A-Z]\", title)\n",
    "        if match3:\n",
    "            index = match3.end(0) - 1\n",
    "            body = title[index:]\n",
    "            body = body.replace(\"  \", \"\\n\\n\")\n",
    "            title = title[:index]\n",
    "        #print(title)\n",
    "    title = remove_empty(title)\n",
    "    if len(title.split('/')) == 3:\n",
    "        title = 'N/A'\n",
    "\n",
    "    return remove_empty(title_number), title, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "footnote_pattern = r'^(\\*|\\d(?![./])|\\d{1}/)\\s.*'\n",
    "\n",
    "# Extract body text (I) and footnote (M)\n",
    "def extract_body(text):\n",
    "    # extract the text content from the second non-empty paragraph\n",
    "    body_text = ''\n",
    "    footnote = []\n",
    "    footnote_idx = 1\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    #print(paragraphs)\n",
    "    \n",
    "    for paragraph in paragraphs:\n",
    "        #for line in paragraph.split('\\n'):\n",
    "            # exclude lines containing specific patterns\n",
    "        paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "        #print(paragraph)\n",
    "        match = re.search(footnote_pattern, paragraph)\n",
    "        if match:\n",
    "            if match.group(0)[0] == '*':\n",
    "                footnote.append(match.group(0))\n",
    "            elif match.group(0)[0] == str(footnote_idx):\n",
    "                footnote.append(match.group(0))\n",
    "                footnote_idx += 1\n",
    "        else:\n",
    "            # if len(paragraph) > 50 or paragraph == \"The General Assembly,\":\n",
    "            #     body_text += paragraph.strip() + ' '\n",
    "            # else:\n",
    "            if len(paragraph) == 0:\n",
    "                continue\n",
    "            if (paragraph[0] == str(footnote_idx) and paragraph[1] == '/') or paragraph[0] == \"*\":\n",
    "                footnote_idx += 1\n",
    "                footnote.append(paragraph) \n",
    "            if not re.search(r'(\\d{2}-\\d{5}|[A-Za-z]/\\d{2}/[A-Za-z]\\.\\d|[A-Za-z ]+Please recycle|Page \\d{1})', paragraph):\n",
    "                body_text += paragraph.strip() + ' '\n",
    "    #print(footnote)\n",
    "    footnote = ' '.join(footnote)\n",
    "    return body_text, footnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify text into column A to N\n",
    "def classify_text_to_column(text):\n",
    "    result = []\n",
    "    \n",
    "    # Split based on : draft, which is the end of countries\n",
    "    part1_text, part2_text = split_text(text)\n",
    "    \n",
    "    # Get year(A) and date(J)\n",
    "    year, date = extract_date(part1_text)\n",
    "\n",
    "    # Get council/committe name (B)\n",
    "    council = extract_council(part1_text)\n",
    "\n",
    "    # Get session (C)\n",
    "    session = extract_session(part1_text)\n",
    "\n",
    "    # Get agenda item (D), agend detail (E), and countries (F)\n",
    "    agenda_item, agenda_detail, countries, footnote1 = extract_agenda_countries(text)\n",
    "\n",
    "    # Get title number (G) and title body (H)\n",
    "    title_number, title_text, body = extract_body_title(part2_text)\n",
    "\n",
    "    # Get Body text (I)\n",
    "    body_text, footnote2 = extract_body(body)\n",
    "    footnote = footnote1 + footnote2\n",
    "    \n",
    "    # Add into result list\n",
    "    result = [year, council, session, agenda_item, agenda_detail, countries, title_number, title_text, body_text, date, footnote]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing the PDF files\n",
    "pdf_folder = './Dataset'\n",
    "\n",
    "# Path to the folder where the CSV files will be saved\n",
    "csv_folder = './csv_folder'\n",
    "\n",
    "# csv file column list\n",
    "column_list = ['year', 'Council', 'Session', 'Agenda item', 'Agenda detail', 'cosponsored countries', \n",
    "               'body title number',\t'body title detail', 'body text', 'date', 'file', 'filecountry', 'footnote', 'scanned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Afghanistan---------------\n",
      "./Dataset/Afghanistan/1995_171257.pdf\n",
      "Afghanistan*, Algeria, Azerbaijan*, Brazil, Colombia, Costa Rica*,\n",
      "Dominican Republic, El Salvador, Guatemala*, Nicaragua, Paraguay*,\n",
      "Peru, Philippines*, Uruguay* and Venezuela\n",
      "./Dataset/Afghanistan/1995_171258.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmy\\Git\\OCR-GAUN\\extract.ipynb Cell 16\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(pdf_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m text \u001b[39m=\u001b[39m extract_text_from_pdf(pdf_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m text_columns \u001b[39m=\u001b[39m classify_text_to_column(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m row \u001b[39m=\u001b[39m text_columns[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m [pdf_file[:\u001b[39m-\u001b[39m\u001b[39m4\u001b[39m], country_folder] \u001b[39m+\u001b[39m text_columns[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:] \u001b[39m#add column K and L\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\lmy\\Git\\OCR-GAUN\\extract.ipynb Cell 16\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_text_from_pdf\u001b[39m(pdf_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Convert the PDF to a list of PIL Image objects\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     images \u001b[39m=\u001b[39m convert_from_path(pdf_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     text_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmy/Git/OCR-GAUN/extract.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Loop through each page of the PDF and extract text using Tesseract\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pdf2image\\pdf2image.py:250\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[1;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mfor\u001b[39;00m uid, proc \u001b[39min\u001b[39;00m processes:\n\u001b[0;32m    249\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         data, err \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39;49mcommunicate(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    251\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired:\n\u001b[0;32m    252\u001b[0m         proc\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:1134\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[0;32m   1135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\subprocess.py:1508\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1504\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1508\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout_thread\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_remaining_time(endtime))\n\u001b[0;32m   1509\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1510\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1059\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1060\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[0;32m   1061\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1062\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1077\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1080\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[0;32m   1081\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1082\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop through each folder and PDF file and extract text\n",
    "for country_folder in os.listdir(pdf_folder):\n",
    "    print('---------------' + country_folder + '---------------' )\n",
    "    if not os.path.isdir(os.path.join(pdf_folder, country_folder)):\n",
    "        continue\n",
    "    \n",
    "    rows = []\n",
    "    count = 0\n",
    "    # Loop through each file \n",
    "    #csv_year = 1994\n",
    "   \n",
    "    for pdf_file in os.listdir(os.path.join(pdf_folder, country_folder)):\n",
    "        if not pdf_file.endswith('.pdf'):\n",
    "            continue\n",
    "        # check if this file is old-version\n",
    "        year = int(pdf_file.split('_')[0])\n",
    "        if year < 1995:\n",
    "            continue\n",
    "\n",
    "        pdf_path = os.path.join(pdf_folder, country_folder, pdf_file).replace('\\\\', '/')\n",
    "        print(pdf_path)\n",
    "        # try:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        text_columns = classify_text_to_column(text)\n",
    "        row = text_columns[:-1] + [pdf_file[:-4], country_folder] + text_columns[-1:] #add column K and L\n",
    "        \n",
    "        # check if year was extracted correctlys\n",
    "        if row[0] != year:\n",
    "            row[0] = year\n",
    "        \n",
    "        # scanned (N), cannot know \n",
    "        if int(year) > 1990:\n",
    "            scanned = 'yes'\n",
    "        else:\n",
    "            scanned = 'no'\n",
    "        row.append(scanned)\n",
    "\n",
    "        rows.append(row)\n",
    "        count += 1\n",
    "        #print(rows)\n",
    "        if year == 1996:\n",
    "            df = pd.DataFrame(rows[:-1], columns = column_list)\n",
    "            csv_path = os.path.join(csv_folder, f\"{country_folder}_{year-1}.csv\")\n",
    "            df.to_csv(csv_path, index = False) \n",
    "            break\n",
    "        # except:\n",
    "        #     print(f\"Error extracting text from {pdf_path}\")\n",
    "        #     continue\n",
    "    break\n",
    "    # Write the rows to the CSV file\n",
    "    df = pd.DataFrame(rows, columns = column_list)\n",
    "    df.to_csv(csv_path, index = False)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE SITUATION IN AFGHANISTAN AND ITS IMPLICATIONS FOR\n",
      "INTERNATIONAL PEACE AND SECURITY\n",
      "Afghanistan\n",
      "('20 (d) and 54', 'STRENGTHENING OF THE COORDINATION OF HUMANITARIAN AND DISASTER RELIEF ASSISTANCE OF THE UNITED NATIONS, INCLUDING SPECIAL ECONOMIC ASSISTANCE: EMERGENCY INTERNATIONAL ASSISTANCE FOR PEACE, NORMALCY AND RECONSTRUCTION OF WAR-STRICKEN AFGHANISTAN', 'Afghanistan', 'THE SITUATION IN AFGHANISTAN AND ITS IMPLICATIONS FOR\\nINTERNATIONAL PEACE AND SECURITY')\n"
     ]
    }
   ],
   "source": [
    "test_list = ['1995_201222.pdf'] #'1995_201150.pdf']#, '1995_201197.pdf', \n",
    "rows = []\n",
    "for test_pdf in test_list:\n",
    "    #if test_pdf == '1994_172588.pdf':\n",
    "    test_text = extract_text_from_pdf(f'./Dataset/Afghanistan/{test_pdf}')\n",
    "    #print(test_text)\n",
    "    #break\n",
    "    p1, p2 = split_text(test_text)\n",
    "    #print(p1)\n",
    "    #print(p2)\n",
    "    # test year and date\n",
    "    #print(extract_date(p1))\n",
    "    #print(extract_council(p1))\n",
    "    #print(extract_session(p1))\n",
    "    print(extract_agenda_countries(test_text))\n",
    "    #t_n, t, b = extract_body_title(p2)\n",
    "    # print(t_n)\n",
    "    # print(t)\n",
    "    #print(b)\n",
    "    #print(extract_body(b))\n",
    "\n",
    "        #rt = re.split(title, p2)\n",
    "        #print(len(rt))\n",
    "        # year = int(test_pdf.split('_')[0])\n",
    "        # text_columns = classify_text_to_column(test_text)\n",
    "        # row = text_columns[:-1] + [test_pdf[:-4], 'country_folder'] + text_columns[-1:] \n",
    "    \n",
    "        # if row[0] != year:\n",
    "        #     row[0] = year\n",
    "\n",
    "        # # scanned (N), cannot know \n",
    "        # if int(year) > 1990:\n",
    "        #     scanned = 'yes'\n",
    "        # else:\n",
    "        #     scanned = 'no'\n",
    "        # row.append(scanned)\n",
    "        # print(row)\n",
    "        # break\n",
    "    #rows.append(row)\n",
    "\n",
    "    #print(rows)\n",
    "    #df = pd.DataFrame(rows, columns = column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 'Fiftieth session\\n Agenda items 20 (d) and 54\\n\\n'\n",
    "m1 = re.search(agenda_pattern, tt)\n",
    "m2 = re.search(agendas_pattern, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 (d) and 54'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.group(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e458c25decc5a85e5a64c322411a3149390d0cc49d8006d301337b209f73e58a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
